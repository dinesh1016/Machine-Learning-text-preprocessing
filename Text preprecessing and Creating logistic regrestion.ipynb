{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa520799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import sklearn\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f7997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\dines\\Downloads\\Text_preprecessing_and_Creating_logistic_regrestion.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08be6549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3efbadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(\"Unnamed: 0\", axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de05c6",
   "metadata": {},
   "source": [
    "## Converting into lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc7060ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       very very good ..i really appreciate vegga for...\n",
       "1       good for day to day use and for those who driv...\n",
       "2       value added product for money:light weight ove...\n",
       "3       worth the pricebought for ₹860pros:- a lot of ...\n",
       "4       well i got this helmet literally for free.. as...\n",
       "                              ...                        \n",
       "5933          nice one ,it's meet my expectationread more\n",
       "5934    lovely...i fell very comfortable in this helme...\n",
       "5935    helmet material is of good quality. i have use...\n",
       "5936                                     perfectread more\n",
       "5937         better to go for studd or steelbirdread more\n",
       "Name: review, Length: 5938, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lowercase(text):\n",
    "    return text.str.lower()\n",
    "\n",
    "df['review'] = lowercase(df['review'])\n",
    "df['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a016f3",
   "metadata": {},
   "source": [
    "## Removehtmltags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2e4cc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       very very good ..i really appreciate vegga for...\n",
       "1       good for day to day use and for those who driv...\n",
       "2       value added product for money:light weight ove...\n",
       "3       worth the pricebought for ₹860pros:- a lot of ...\n",
       "4       well i got this helmet literally for free.. as...\n",
       "                              ...                        \n",
       "5933          nice one ,it's meet my expectationread more\n",
       "5934    lovely...i fell very comfortable in this helme...\n",
       "5935    helmet material is of good quality. i have use...\n",
       "5936                                     perfectread more\n",
       "5937         better to go for studd or steelbirdread more\n",
       "Name: review, Length: 5938, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def removehtmltags(text):\n",
    "    return re.sub(r'<.*?>','',text)\n",
    "    \n",
    "df['review']= df['review'].apply(removehtmltags)\n",
    "df['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244f6c9c",
   "metadata": {},
   "source": [
    "## Remove Urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "998a05c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       very very good ..i really appreciate vegga for...\n",
       "1       good for day to day use and for those who driv...\n",
       "2       value added product for money:light weight ove...\n",
       "3       worth the pricebought for ₹860pros:- a lot of ...\n",
       "4       well i got this helmet literally for free.. as...\n",
       "                              ...                        \n",
       "5933          nice one ,it's meet my expectationread more\n",
       "5934    lovely...i fell very comfortable in this helme...\n",
       "5935    helmet material is of good quality. i have use...\n",
       "5936                                     perfectread more\n",
       "5937         better to go for studd or steelbirdread more\n",
       "Name: review, Length: 5938, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def removeurls(text):\n",
    "    return re.sub('http?s://\\s+|www\\.s\\+', \" \", text)\n",
    "\n",
    "df['review'] = df['review'].apply(removeurls)\n",
    "df['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e191143",
   "metadata": {},
   "source": [
    "## handle new line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87abc6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handlenewline(text):\n",
    "    return re.sub('\\n|\\r',\" \", text)\n",
    "df[\"review\"] = df['review'].apply(handlenewline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ca30fd",
   "metadata": {},
   "source": [
    "## removing read me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caebe6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removereadme(text):\n",
    "    return re.sub('READ ME','',text)\n",
    "df['return'] = df['review'].apply(removereadme)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a311bb5",
   "metadata": {},
   "source": [
    "## remove special charecters/punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92fb1ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removespecialchars(text):\n",
    "    return re.sub('[^0-9a-zA-Z]',\" \",text)\n",
    "df['review'] = df['review'].apply(removespecialchars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46354b5b",
   "metadata": {},
   "source": [
    "## remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01c455a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ravi\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19d78eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removestopwords(text):\n",
    "\n",
    "    a = []\n",
    "    for word in text.split(' '):\n",
    "        if word not in stopwords.words('english'):\n",
    "            a.append(word)\n",
    "    return ' '.join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4b94e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good   really appreciate vegga helmet  cheap p...</td>\n",
       "      <td>5</td>\n",
       "      <td>very very good ..i really appreciate vegga for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good day day use drives safely  quality good  ...</td>\n",
       "      <td>4</td>\n",
       "      <td>good for day to day use and for those who driv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>value added product money light weight head ma...</td>\n",
       "      <td>5</td>\n",
       "      <td>value added product for money:light weight ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>worth pricebought  860pros   lot space glass f...</td>\n",
       "      <td>4</td>\n",
       "      <td>worth the pricebought for ₹860pros:- a lot of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well got helmet literally free   flipkart plus...</td>\n",
       "      <td>5</td>\n",
       "      <td>well i got this helmet literally for free.. as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating  \\\n",
       "0  good   really appreciate vegga helmet  cheap p...       5   \n",
       "1  good day day use drives safely  quality good  ...       4   \n",
       "2  value added product money light weight head ma...       5   \n",
       "3  worth pricebought  860pros   lot space glass f...       4   \n",
       "4  well got helmet literally free   flipkart plus...       5   \n",
       "\n",
       "                                              return  \n",
       "0  very very good ..i really appreciate vegga for...  \n",
       "1  good for day to day use and for those who driv...  \n",
       "2  value added product for money:light weight ove...  \n",
       "3  worth the pricebought for ₹860pros:- a lot of ...  \n",
       "4  well i got this helmet literally for free.. as...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(removestopwords)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffec7977",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(\"return\", axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c262f493",
   "metadata": {},
   "source": [
    "## convert tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79a28abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converttokens(data, colName):\n",
    "    x= colName + \"_wordTokens\"\n",
    "    data[x] = data[colName].str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "306aa337",
   "metadata": {},
   "outputs": [],
   "source": [
    "converttokens(df, 'review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23ea9aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_wordTokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good   really appreciate vegga helmet  cheap p...</td>\n",
       "      <td>5</td>\n",
       "      <td>[good, , , really, appreciate, vegga, helmet, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good day day use drives safely  quality good  ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[good, day, day, use, drives, safely, , qualit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>value added product money light weight head ma...</td>\n",
       "      <td>5</td>\n",
       "      <td>[value, added, product, money, light, weight, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>worth pricebought  860pros   lot space glass f...</td>\n",
       "      <td>4</td>\n",
       "      <td>[worth, pricebought, , 860pros, , , lot, space...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well got helmet literally free   flipkart plus...</td>\n",
       "      <td>5</td>\n",
       "      <td>[well, got, helmet, literally, free, , , flipk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>nice one  meet expectationread</td>\n",
       "      <td>3</td>\n",
       "      <td>[nice, one, , meet, expectationread]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>lovely   fell comfortable helmet   read</td>\n",
       "      <td>1</td>\n",
       "      <td>[lovely, , , fell, comfortable, helmet, , , read]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>helmet material good quality  used 6 months  n...</td>\n",
       "      <td>5</td>\n",
       "      <td>[helmet, material, good, quality, , used, 6, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>perfectread</td>\n",
       "      <td>5</td>\n",
       "      <td>[perfectread]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5937</th>\n",
       "      <td>better go studd steelbirdread</td>\n",
       "      <td>4</td>\n",
       "      <td>[better, go, studd, steelbirdread]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5938 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  rating  \\\n",
       "0     good   really appreciate vegga helmet  cheap p...       5   \n",
       "1     good day day use drives safely  quality good  ...       4   \n",
       "2     value added product money light weight head ma...       5   \n",
       "3     worth pricebought  860pros   lot space glass f...       4   \n",
       "4     well got helmet literally free   flipkart plus...       5   \n",
       "...                                                 ...     ...   \n",
       "5933                     nice one  meet expectationread       3   \n",
       "5934            lovely   fell comfortable helmet   read       1   \n",
       "5935  helmet material good quality  used 6 months  n...       5   \n",
       "5936                                        perfectread       5   \n",
       "5937                      better go studd steelbirdread       4   \n",
       "\n",
       "                                      review_wordTokens  \n",
       "0     [good, , , really, appreciate, vegga, helmet, ...  \n",
       "1     [good, day, day, use, drives, safely, , qualit...  \n",
       "2     [value, added, product, money, light, weight, ...  \n",
       "3     [worth, pricebought, , 860pros, , , lot, space...  \n",
       "4     [well, got, helmet, literally, free, , , flipk...  \n",
       "...                                                 ...  \n",
       "5933               [nice, one, , meet, expectationread]  \n",
       "5934  [lovely, , , fell, comfortable, helmet, , , read]  \n",
       "5935  [helmet, material, good, quality, , used, 6, m...  \n",
       "5936                                      [perfectread]  \n",
       "5937                 [better, go, studd, steelbirdread]  \n",
       "\n",
       "[5938 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcecc25",
   "metadata": {},
   "source": [
    "## lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ff351bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Ravi\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Ravi\n",
      "[nltk_data]     Kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56d190bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemTokens(text):\n",
    "    lemTokens = []\n",
    "    for word in text.split(' '):\n",
    "        \n",
    "        if word != ' ' or word !='':\n",
    "            lemTokens.append(lem.lemmatize(word))\n",
    "    return lemTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "324c2734",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemTokens\"] = df[\"review\"].apply(lemTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "312f7548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_wordTokens</th>\n",
       "      <th>lemTokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good   really appreciate vegga helmet  cheap p...</td>\n",
       "      <td>5</td>\n",
       "      <td>[good, , , really, appreciate, vegga, helmet, ...</td>\n",
       "      <td>[good, , , really, appreciate, vegga, helmet, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good day day use drives safely  quality good  ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[good, day, day, use, drives, safely, , qualit...</td>\n",
       "      <td>[good, day, day, use, drive, safely, , quality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>value added product money light weight head ma...</td>\n",
       "      <td>5</td>\n",
       "      <td>[value, added, product, money, light, weight, ...</td>\n",
       "      <td>[value, added, product, money, light, weight, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>worth pricebought  860pros   lot space glass f...</td>\n",
       "      <td>4</td>\n",
       "      <td>[worth, pricebought, , 860pros, , , lot, space...</td>\n",
       "      <td>[worth, pricebought, , 860pros, , , lot, space...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well got helmet literally free   flipkart plus...</td>\n",
       "      <td>5</td>\n",
       "      <td>[well, got, helmet, literally, free, , , flipk...</td>\n",
       "      <td>[well, got, helmet, literally, free, , , flipk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating  \\\n",
       "0  good   really appreciate vegga helmet  cheap p...       5   \n",
       "1  good day day use drives safely  quality good  ...       4   \n",
       "2  value added product money light weight head ma...       5   \n",
       "3  worth pricebought  860pros   lot space glass f...       4   \n",
       "4  well got helmet literally free   flipkart plus...       5   \n",
       "\n",
       "                                   review_wordTokens  \\\n",
       "0  [good, , , really, appreciate, vegga, helmet, ...   \n",
       "1  [good, day, day, use, drives, safely, , qualit...   \n",
       "2  [value, added, product, money, light, weight, ...   \n",
       "3  [worth, pricebought, , 860pros, , , lot, space...   \n",
       "4  [well, got, helmet, literally, free, , , flipk...   \n",
       "\n",
       "                                           lemTokens  \n",
       "0  [good, , , really, appreciate, vegga, helmet, ...  \n",
       "1  [good, day, day, use, drive, safely, , quality...  \n",
       "2  [value, added, product, money, light, weight, ...  \n",
       "3  [worth, pricebought, , 860pros, , , lot, space...  \n",
       "4  [well, got, helmet, literally, free, , , flipk...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0f1cd6",
   "metadata": {},
   "source": [
    "## converting lem tokens into lem sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f317462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemSentences\"] = df[\"lemTokens\"].str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b180784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_wordTokens</th>\n",
       "      <th>lemTokens</th>\n",
       "      <th>lemSentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good   really appreciate vegga helmet  cheap p...</td>\n",
       "      <td>5</td>\n",
       "      <td>[good, , , really, appreciate, vegga, helmet, ...</td>\n",
       "      <td>[good, , , really, appreciate, vegga, helmet, ...</td>\n",
       "      <td>good   really appreciate vegga helmet  cheap p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good day day use drives safely  quality good  ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[good, day, day, use, drives, safely, , qualit...</td>\n",
       "      <td>[good, day, day, use, drive, safely, , quality...</td>\n",
       "      <td>good day day use drive safely  quality good  l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>value added product money light weight head ma...</td>\n",
       "      <td>5</td>\n",
       "      <td>[value, added, product, money, light, weight, ...</td>\n",
       "      <td>[value, added, product, money, light, weight, ...</td>\n",
       "      <td>value added product money light weight head ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>worth pricebought  860pros   lot space glass f...</td>\n",
       "      <td>4</td>\n",
       "      <td>[worth, pricebought, , 860pros, , , lot, space...</td>\n",
       "      <td>[worth, pricebought, , 860pros, , , lot, space...</td>\n",
       "      <td>worth pricebought  860pros   lot space glass f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well got helmet literally free   flipkart plus...</td>\n",
       "      <td>5</td>\n",
       "      <td>[well, got, helmet, literally, free, , , flipk...</td>\n",
       "      <td>[well, got, helmet, literally, free, , , flipk...</td>\n",
       "      <td>well got helmet literally free   flipkart plus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>nice one  meet expectationread</td>\n",
       "      <td>3</td>\n",
       "      <td>[nice, one, , meet, expectationread]</td>\n",
       "      <td>[nice, one, , meet, expectationread]</td>\n",
       "      <td>nice one  meet expectationread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>lovely   fell comfortable helmet   read</td>\n",
       "      <td>1</td>\n",
       "      <td>[lovely, , , fell, comfortable, helmet, , , read]</td>\n",
       "      <td>[lovely, , , fell, comfortable, helmet, , , read]</td>\n",
       "      <td>lovely   fell comfortable helmet   read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>helmet material good quality  used 6 months  n...</td>\n",
       "      <td>5</td>\n",
       "      <td>[helmet, material, good, quality, , used, 6, m...</td>\n",
       "      <td>[helmet, material, good, quality, , used, 6, m...</td>\n",
       "      <td>helmet material good quality  used 6 month  ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>perfectread</td>\n",
       "      <td>5</td>\n",
       "      <td>[perfectread]</td>\n",
       "      <td>[perfectread]</td>\n",
       "      <td>perfectread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5937</th>\n",
       "      <td>better go studd steelbirdread</td>\n",
       "      <td>4</td>\n",
       "      <td>[better, go, studd, steelbirdread]</td>\n",
       "      <td>[better, go, studd, steelbirdread]</td>\n",
       "      <td>better go studd steelbirdread</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5938 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  rating  \\\n",
       "0     good   really appreciate vegga helmet  cheap p...       5   \n",
       "1     good day day use drives safely  quality good  ...       4   \n",
       "2     value added product money light weight head ma...       5   \n",
       "3     worth pricebought  860pros   lot space glass f...       4   \n",
       "4     well got helmet literally free   flipkart plus...       5   \n",
       "...                                                 ...     ...   \n",
       "5933                     nice one  meet expectationread       3   \n",
       "5934            lovely   fell comfortable helmet   read       1   \n",
       "5935  helmet material good quality  used 6 months  n...       5   \n",
       "5936                                        perfectread       5   \n",
       "5937                      better go studd steelbirdread       4   \n",
       "\n",
       "                                      review_wordTokens  \\\n",
       "0     [good, , , really, appreciate, vegga, helmet, ...   \n",
       "1     [good, day, day, use, drives, safely, , qualit...   \n",
       "2     [value, added, product, money, light, weight, ...   \n",
       "3     [worth, pricebought, , 860pros, , , lot, space...   \n",
       "4     [well, got, helmet, literally, free, , , flipk...   \n",
       "...                                                 ...   \n",
       "5933               [nice, one, , meet, expectationread]   \n",
       "5934  [lovely, , , fell, comfortable, helmet, , , read]   \n",
       "5935  [helmet, material, good, quality, , used, 6, m...   \n",
       "5936                                      [perfectread]   \n",
       "5937                 [better, go, studd, steelbirdread]   \n",
       "\n",
       "                                              lemTokens  \\\n",
       "0     [good, , , really, appreciate, vegga, helmet, ...   \n",
       "1     [good, day, day, use, drive, safely, , quality...   \n",
       "2     [value, added, product, money, light, weight, ...   \n",
       "3     [worth, pricebought, , 860pros, , , lot, space...   \n",
       "4     [well, got, helmet, literally, free, , , flipk...   \n",
       "...                                                 ...   \n",
       "5933               [nice, one, , meet, expectationread]   \n",
       "5934  [lovely, , , fell, comfortable, helmet, , , read]   \n",
       "5935  [helmet, material, good, quality, , used, 6, m...   \n",
       "5936                                      [perfectread]   \n",
       "5937                 [better, go, studd, steelbirdread]   \n",
       "\n",
       "                                           lemSentences  \n",
       "0     good   really appreciate vegga helmet  cheap p...  \n",
       "1     good day day use drive safely  quality good  l...  \n",
       "2     value added product money light weight head ma...  \n",
       "3     worth pricebought  860pros   lot space glass f...  \n",
       "4     well got helmet literally free   flipkart plus...  \n",
       "...                                                 ...  \n",
       "5933                     nice one  meet expectationread  \n",
       "5934            lovely   fell comfortable helmet   read  \n",
       "5935  helmet material good quality  used 6 month  ni...  \n",
       "5936                                        perfectread  \n",
       "5937                      better go studd steelbirdread  \n",
       "\n",
       "[5938 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a310a4",
   "metadata": {},
   "source": [
    "## splitting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e07750bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d67c53c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['lemSentences']]\n",
    "y = df[['rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88bf5354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4750, 1), (1188, 1), 4750, 1188)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain,xTest,yTrain,yTest = train_test_split(x,y,\n",
    "                                            test_size =0.2)\n",
    "\n",
    "\n",
    "xTrain.shape, xTest.shape, len(yTrain), len(yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52396a9d",
   "metadata": {},
   "source": [
    "## creating a model for count vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6fba93",
   "metadata": {},
   "source": [
    "### for bag of unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04c4cad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "countvectorizer=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3257ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "countXTrain=countvectorizer.fit_transform(xTrain[\"lemSentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82f4cbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4750x2828 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 21509 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countXTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4140a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "countXTest=countvectorizer.transform(xTest[\"lemSentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ad7f890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1188x2828 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5040 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countXTest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5135e73b",
   "metadata": {},
   "source": [
    "## creating a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af4d25dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score as acs\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "LR = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78411074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ravi Kumar\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Ravi Kumar\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.fit(countXTrain,yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a57a0b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "YTrainpred=LR.predict(countXTrain)\n",
    "YTestpred=LR.predict(countXTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a197657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7063157894736842, 0.5707070707070707)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs(yTrain,YTrainpred),acs(yTest,YTestpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1307b8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  11,    0,    0,    1,   54],\n",
       "        [   0,    4,    2,    1,   51],\n",
       "        [   0,    0,   78,   18,  393],\n",
       "        [   1,    0,    2,  468,  829],\n",
       "        [   0,    0,    1,   42, 2794]], dtype=int64),\n",
       " array([[  0,   0,   0,   0,  12],\n",
       "        [  0,   0,   0,   0,  20],\n",
       "        [  0,   0,   1,   7,  95],\n",
       "        [  0,   0,   3,  27, 304],\n",
       "        [  0,   0,   2,  67, 650]], dtype=int64))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yTrain,YTrainpred),confusion_matrix(yTest,YTestpred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd2423",
   "metadata": {},
   "source": [
    "## for bag of uni - bi grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31420686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvectorizer=CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "bixTrain=countvectorizer.fit_transform(xTrain[\"lemSentences\"])\n",
    "bixTrain.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d712651a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bixTest=countvectorizer.transform(xTest[\"lemSentences\"])\n",
    "bixTest.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21bc7aa",
   "metadata": {},
   "source": [
    "## creating a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c2cbfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ravi Kumar\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Ravi Kumar\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "LR.fit(bixTrain,yTrain)\n",
    "\n",
    "YTrainpred=LR.predict(bixTrain)\n",
    "YTestpred=LR.predict(bixTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59c6e174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8227368421052632, 0.5521885521885522)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the accuracy score and confusion matrix\n",
    "\n",
    "acs(yTrain,YTrainpred),acs(yTest,YTestpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f31a781f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  18,    0,    0,    6,   42],\n",
       "        [   0,   12,    0,    2,   44],\n",
       "        [   0,    0,  243,   22,  224],\n",
       "        [   0,    0,    2,  840,  458],\n",
       "        [   0,    0,    0,   42, 2795]], dtype=int64),\n",
       " array([[  0,   0,   0,   1,  11],\n",
       "        [  0,   0,   0,   0,  20],\n",
       "        [  0,   0,   1,  11,  91],\n",
       "        [  0,   0,   1,  30, 303],\n",
       "        [  0,   0,   6,  88, 625]], dtype=int64))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yTrain,YTrainpred),confusion_matrix(yTest,YTestpred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f67cdf",
   "metadata": {},
   "source": [
    "## creating a mode for tfidfvectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeab070",
   "metadata": {},
   "source": [
    "### for tfidf bag of uni grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ab5804e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf=TfidfVectorizer()\n",
    "\n",
    "tfunixTrain=tfidf.fit_transform(xTrain[\"lemSentences\"])\n",
    "tfunixTrain.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e63ffe4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfunixTest=tfidf.transform(xTest[\"lemSentences\"])\n",
    "tfunixTest.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157cd017",
   "metadata": {},
   "source": [
    "## creating a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82872e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ravi Kumar\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "LR.fit(tfunixTrain,yTrain)\n",
    "\n",
    "YTrainpred=LR.predict(tfunixTrain)\n",
    "YTestpred=LR.predict(tfunixTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "422d0dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6385263157894737, 0.5925925925925926)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the accuracy score and confusion matrix\n",
    "\n",
    "acs(yTrain,YTrainpred),acs(yTest,YTestpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe080819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   0,    0,    0,    2,   64],\n",
       "        [   0,    0,    0,    3,   55],\n",
       "        [   0,    0,    2,   16,  471],\n",
       "        [   0,    0,    0,  218, 1082],\n",
       "        [   0,    0,    0,   24, 2813]], dtype=int64),\n",
       " array([[  0,   0,   0,   0,  12],\n",
       "        [  0,   0,   0,   0,  20],\n",
       "        [  0,   0,   0,   5,  98],\n",
       "        [  0,   0,   0,  15, 319],\n",
       "        [  0,   0,   0,  30, 689]], dtype=int64))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yTrain,YTrainpred),confusion_matrix(yTest,YTestpred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f3029",
   "metadata": {},
   "source": [
    "## tfidf bag of uni - bi grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "576932fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfuni_biVec=TfidfVectorizer(ngram_range = (1,2))\n",
    "\n",
    "tfbixTrain=tfuni_biVec.fit_transform(xTrain[\"lemSentences\"])\n",
    "tfbixTrain.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1db87584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfbixTest=tfuni_biVec.transform(xTrain[\"lemSentences\"])\n",
    "tfbixTest.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae456394",
   "metadata": {},
   "source": [
    "## creating a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d38a8bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ravi Kumar\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "LR.fit(tfbixTrain,yTrain)\n",
    "\n",
    "yTrainpred=LR.predict(tfbixTrain)\n",
    "yTestpred=LR.predict(tfbixTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71ec6ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6795789473684211"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs(yTrain,yTrainpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e751ad00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    2,   64],\n",
       "       [   0,    0,    0,    3,   55],\n",
       "       [   0,    0,    2,   16,  471],\n",
       "       [   0,    0,    0,  218, 1082],\n",
       "       [   0,    0,    0,   24, 2813]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yTrain,YTrainpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d7e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
